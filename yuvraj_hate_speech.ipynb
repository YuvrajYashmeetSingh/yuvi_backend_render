{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9174f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn. feature_extraction. text import CountVectorizer\n",
    "from sklearn. model_selection import train_test_split\n",
    "from sklearn. tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92d508a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
      "0           0      3            0                   0        3      2   \n",
      "1           1      3            0                   3        0      1   \n",
      "2           2      3            0                   3        0      1   \n",
      "3           3      3            0                   2        1      1   \n",
      "4           4      6            0                   6        0      1   \n",
      "5           5      3            1                   2        0      1   \n",
      "6           6      3            0                   3        0      1   \n",
      "\n",
      "                                               tweet  \n",
      "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
      "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
      "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
      "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
      "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n",
      "5  !!!!!!!!!!!!!!!!!!\"@T_Madison_x: The shit just...  \n",
      "6  !!!!!!\"@__BrighterDays: I can not just sit up ...  \n"
     ]
    }
   ],
   "source": [
    "data = pd. read_csv(\"labeled_data.csv\")\n",
    "#To preview the data\n",
    "print(data. head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895aa96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "#nltk. download('stopwords')\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97401120",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\yuvib\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')  # Download stopwords corpus if not already downloaded\n",
    "stopword = set(stopwords.words('english'))\n",
    "stemmer = nltk.SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe25b1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               tweet  \\\n",
      "0  !!! RT @mayasolovely: As a woman you shouldn't...   \n",
      "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   \n",
      "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   \n",
      "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   \n",
      "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   \n",
      "5  !!!!!!!!!!!!!!!!!!\"@T_Madison_x: The shit just...   \n",
      "6  !!!!!!\"@__BrighterDays: I can not just sit up ...   \n",
      "\n",
      "                         labels  \n",
      "0  No Hate and Offensive Speech  \n",
      "1              Offensive Speech  \n",
      "2              Offensive Speech  \n",
      "3              Offensive Speech  \n",
      "4              Offensive Speech  \n",
      "5              Offensive Speech  \n",
      "6              Offensive Speech  \n"
     ]
    }
   ],
   "source": [
    "data[\"labels\"] = data[\"class\"]. map({0: \"Hate Speech\", 1: \"Offensive Speech\", 2: \"No Hate and Offensive Speech\"})\n",
    "data = data[[\"tweet\", \"labels\"]]\n",
    "print(data. head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8de8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\yuvib\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "# Initialize stopwords and stemmer\n",
    "nltk.download('stopwords')\n",
    "stopwords_set = set(stopwords.words('english'))\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "# Define the clean function\n",
    "def clean(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('[.?]', '', text)\n",
    "    text = re.sub('https?://\\S+|www.\\S+', '', text)\n",
    "    text = re.sub('<.?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w\\d\\w', '', text)\n",
    "    text = [word for word in text.split(' ') if word not in stopwords_set]\n",
    "    text = \" \".join(text)\n",
    "    text = [stemmer.stem(word) for word in text.split(' ')]\n",
    "    text = \" \".join(text)\n",
    "    return text\n",
    "\n",
    "# Assuming 'data' is your DataFrame\n",
    "data[\"tweet\"] = data[\"tweet\"].apply(clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1288ae15",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np. array(data[\"tweet\"])\n",
    "y = np. array(data[\"labels\"])\n",
    "cv = CountVectorizer()\n",
    "X = cv. fit_transform(x)\n",
    "# Splitting the Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9395e588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model building\n",
    "model = DecisionTreeClassifier()\n",
    "#Training the model\n",
    "model. fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222b1c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Offensive Speech', 'Offensive Speech', 'Offensive Speech', ...,\n",
       "       'No Hate and Offensive Speech', 'Offensive Speech',\n",
       "       'Offensive Speech'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing the model\n",
    "y_pred = model. predict (X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305369b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8784692505196234\n"
     ]
    }
   ],
   "source": [
    "#Accuracy Score of our model\n",
    "from sklearn. metrics import accuracy_score\n",
    "print (accuracy_score (y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf2b5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No Hate and Offensive Speech']\n"
     ]
    }
   ],
   "source": [
    "#Predicting the outcome\n",
    "inp = \"You are too bad and I dont like your attitude\"\n",
    "inp = cv.transform([inp]).toarray()\n",
    "print(model.predict(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03da8202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No Hate and Offensive Speech']\n"
     ]
    }
   ],
   "source": [
    "inp = \"It is really awesome\"\n",
    "inp = cv. transform([inp]). toarray()\n",
    "print(model. predict(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6b832e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Offensive Speech']\n"
     ]
    }
   ],
   "source": [
    "inp = \"fuck you\"\n",
    "inp = cv. transform([inp]). toarray()\n",
    "print(model. predict(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee7b89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Offensive Speech']\n"
     ]
    }
   ],
   "source": [
    "inp = \"your are idiot man\"\n",
    "inp = cv. transform([inp]). toarray()\n",
    "print(model. predict(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab3bcbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No Hate and Offensive Speech']\n"
     ]
    }
   ],
   "source": [
    "inp = \"your are killing me\"\n",
    "inp = cv. transform([inp]). toarray()\n",
    "print(model. predict(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4a61c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hate Speech']\n"
     ]
    }
   ],
   "source": [
    "inp = \"go to hell man\"\n",
    "inp = cv. transform([inp]). toarray()\n",
    "print(model. predict(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1e5dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No Hate and Offensive Speech']\n"
     ]
    }
   ],
   "source": [
    "inp = \"your looking fucking awsawesome \"\n",
    "inp = cv. transform([inp]). toarray()\n",
    "print(model. predict(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1eca8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No Hate and Offensive Speech']\n"
     ]
    }
   ],
   "source": [
    "inp = \"good morning\"\n",
    "inp = cv. transform([inp]). toarray()\n",
    "print(model. predict(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b7a859",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = \"fucking awseome\"\n",
    "inp = cv. transform([inp]). toarray()\n",
    "print(model. predict(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f50527",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
